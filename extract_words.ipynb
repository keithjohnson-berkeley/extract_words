{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tIwN_-ZVDlLD"
   },
   "source": [
    "## Extract words for speech perception stimuli\n",
    "\n",
    "This script reads Praat textgrid files and extracts audio clips of selected words.\n",
    "\n",
    "It uses the python wrapper for sox, and Ronald Sprouse's audiolabel library and dir2df function.\n",
    "\n",
    "The script also converts the audio to 22050 sampling rate, one channel,\n",
    "and normalizes the amplitude so the peak amplitude is 2dB below max\n",
    "\n",
    "    tfm.convert(samplerate=22050, n_channels=1)\n",
    "    tfm.norm(-2)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 948,
     "status": "ok",
     "timestamp": 1671128666108,
     "user": {
      "displayName": "Kevin McGowan",
      "userId": "06925105031902135324"
     },
     "user_tz": 300
    },
    "id": "ZlaPwK_nDlLF"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from sox import Transformer\n",
    "from audiolabel import read_label   # Ronald Sprouse's audiolabel library - to read TextGrid files\n",
    "from phonlab.utils import dir2df    # Ronald Sprouse's dir2df - to make a dataframe from a directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KdmN6iUjDlLH"
   },
   "source": [
    "## Context\n",
    "\n",
    "Set some context variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1671128666109,
     "user": {
      "displayName": "Kevin McGowan",
      "userId": "06925105031902135324"
     },
     "user_tz": 300
    },
    "id": "DpbpSxUnDlLI"
   },
   "outputs": [],
   "source": [
    "target_words = [\"PEOPLE\",\"TOLD\"]   # list the words that we want to extract (if not all of them)\n",
    "pad = 0.01  # pad the duration taken (before and after), in seconds\n",
    "\n",
    "word_tier = \"Word\"  # the name of the word tier in the textgrids\n",
    "\n",
    "# where to find the text grids and wav files\n",
    "tgdir = Path('/Users/kjohnson/Downloads/Sound files and text grids')\n",
    "wavdir = Path('/Users/kjohnson/Downloads/Sound files and text grids')\n",
    "outdir = Path('/Users/kjohnson/Downloads/Sound files and text grids/words_for_perception_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of all of the text grids in this corpus\n",
    "\n",
    "tgdf = dir2df(tgdir, fnpat='\\.TextGrid$', addcols=['barename'])\n",
    "print(f'Found {len(tgdf)} .TextGrid files.')\n",
    "\n",
    "tgdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working on things\n",
    "\n",
    "Debugging and making sure that this works okay on one example textgrid file\n",
    "before letting the thing loose on all of the textgrids in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = tgdf.iloc[0]  # an example file\n",
    "\n",
    "wddf = read_label(str(tgdir / row.relpath / row.fname), ftype='praat',tiers=word_tier)[0]\n",
    "input_audio = str(wavdir / row.relpath / row.barename)+\".wav\"\n",
    "\n",
    "word_list = {}  # a dictionary to count instances of words\n",
    "\n",
    "print(input_audio)\n",
    "\n",
    "# two versions of this loop\n",
    "\n",
    "for index, word_label in wddf[wddf[word_tier]!=''].iterrows():  # extract all words\n",
    "#for index, word_row in wddf[wddf[word_tier].isin(target_words)].iterrows():  # extract target words\n",
    "\n",
    "    word = word_label[word_tier]\n",
    "        \n",
    "    try:\n",
    "        word_list[word] += 1   # if there are more than one instance of word [word] they will be numbered\n",
    "    except:\n",
    "        word_list[word] = 0\n",
    "    \n",
    "    start = word_label.t1 - pad\n",
    "    end = word_label.t2 + pad\n",
    "    output_wav = '_'.join((row.barename,word,str(word_list[word])))+\".wav\"\n",
    "    output_mp3 = '_'.join((row.barename,word,str(word_list[word])))+\".mp3\"\n",
    "\n",
    "    print(str(outdir / output_wav), start, end)\n",
    "    \n",
    "    # use sox to clip out the word\n",
    "    tfm = Transformer()  # create a transformer object\n",
    "    \n",
    "    tfm.trim(start,end)   # set the parameters of the transformer\n",
    "    tfm.convert(samplerate=22050, n_channels=1)\n",
    "    tfm.norm(-2)\n",
    "    \n",
    "    #tfm.build(input_audio,str(outdir / output_wav))  \n",
    "    #tfm.build(input_audio,str(outdir / output_mp3))\n",
    "    \n",
    "wddf.head()\n",
    "word_row\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process all files.\n",
    "\n",
    "Now we can loop over all of the files in the corpus, extracting our target words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in tgdf.itertuples():   # loop through all of the textgrids\n",
    "\n",
    "    wddf = read_label(str(tgdir / row.relpath / row.fname), ftype='praat',tiers=word_tier)[0]\n",
    "    input_audio = str(wavdir / row.relpath / row.barename)+\".wav\"\n",
    "    \n",
    "    word_list = {}  # a dictionary to count instances of words\n",
    "\n",
    "    print(input_audio)\n",
    "    \n",
    "    # two versions of this loop\n",
    "\n",
    "    for index, word_label in wddf[wddf[word_tier]!=''].iterrows():  # extract all words\n",
    "    #for index, word_row in wddf[wddf[word_tier].isin(target_words)].iterrows():  # extract target words\n",
    "\n",
    "        word = word_label[word_tier]\n",
    "        \n",
    "        try:\n",
    "            word_list[word] += 1   # if there are more than one instance of word [word] they will be numbered\n",
    "        except:\n",
    "            word_list[word] = 0\n",
    "    \n",
    "        start = word_label.t1 - pad\n",
    "        end = word_label.t2 + pad\n",
    "        output_wav = '_'.join((row.barename,word,str(word_list[word])))+\".wav\"\n",
    "        output_mp3 = '_'.join((row.barename,word,str(word_list[word])))+\".mp3\"\n",
    "\n",
    "        #print(str(outdir / output_wav), start, end)\n",
    "    \n",
    "        # use sox to clip out the word\n",
    "        tfm = Transformer()  # create a transformer object\n",
    "        tfm.trim(start,end)   # set the parameters of the transformer\n",
    "        tfm.convert(samplerate=22050, n_channels=1)\n",
    "        tfm.norm(-2)\n",
    "        tfm.build(input_audio,str(outdir / output_wav))  \n",
    "        tfm.build(input_audio,str(outdir / output_mp3))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
